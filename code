import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier

pip install xgboost


sonar_data = pd.read_csv('/content/Copy of sonar data.csv', header=None)

sonar_data.head()

# number of rows and columns
sonar_data.shape

sonar_data.describe()  #describe --> statistical measures of the data

sonar_data[60].value_counts()

sonar_data.groupby(60).mean()

X = sonar_data.drop(columns=60, axis=1)
Y = sonar_data[60]

print(X)
print(Y)

label_encoder = LabelEncoder()
Y_encoded = label_encoder.fit_transform(Y)

X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y_encoded, test_size=0.4, stratify=Y_encoded, random_state=1
)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=1),
    'Random Forest': RandomForestClassifier(random_state=1),
    'SVM': SVC(kernel='linear'),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Naive Bayes': GaussianNB(),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    'AdaBoost': AdaBoostClassifier(random_state=1)
}


for name, model in models.items():
    model.fit(X_train_scaled, Y_train)
    train_pred = model.predict(X_train_scaled)
    test_pred = model.predict(X_test_scaled)

    train_acc = accuracy_score(Y_train, train_pred)
    test_acc = accuracy_score(Y_test, test_pred)

    print(f'=== {name} ===')
    print('Training Accuracy :', train_acc)
    print('Test Accuracy     :', test_acc)
    print()

input_data = (0.0181,0.0146,0.0026,0.0141,0.0421,0.0473,0.0361,0.0741,0.1398,0.1045,0.0904,0.0671,0.0997,0.1056,0.0346,0.1231,0.1626,0.3652,0.3262,0.2995,0.2109,0.2104,0.2085,0.2282,0.0747,0.1969,0.4086,0.6385,0.7970,0.7508,0.5517,0.2214,0.4672,0.4479,0.2297,0.3235,0.4480,0.5581,0.6520,0.5354,0.2478,0.2268,0.1788,0.0898,0.0536,0.0374,0.0990,0.0956,0.0317,0.0142,0.0076,0.0223,0.0255,0.0145,0.0233,0.0041,0.0018,0.0048,0.0089,0.0085

)
input_data_reshaped = np.asarray(input_data).reshape(1, -1)
input_data_scaled = scaler.transform(input_data_reshaped)


for name, model in models.items():
    prediction = model.predict(input_data_scaled)
    label = label_encoder.inverse_transform(prediction)[0]
    result = 'Rock' if label == 'R' else 'Mine'
    print(f'{name} Prediction: The object is a {result}')

input_data_reshaped = np.asarray(input_data).reshape(1, -1)
input_data_scaled = scaler.transform(input_data_reshaped)

print("\nPredictions for the input data:")
for name, model in models.items():
    prediction = model.predict(input_data_scaled)
    label = label_encoder.inverse_transform(prediction)[0]
    result = 'Rock' if label == 'R' else 'Mine'
    print(f'{name}: The object is a {result}')
